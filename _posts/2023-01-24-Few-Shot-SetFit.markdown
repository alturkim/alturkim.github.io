---
layout: post
title:  "Few Shot Learning with Sentence Transformers: SetFit
"
date:   2023-01-23 15:39:08 +0300
categories: jekyll update
---
Few Shot Learning refers to a learning paradigm where few labeled data are used to train a model with the expectation that performance will be comparable to situations where the model is trained on large amount of data.
To achieve this goal, researchers have come up with several techniques. A general theme in Few-shot Learning in NLP is to prompt a language model.
Large Language Models (LLMs) have been shown to possess surprising capabilities in term of solving tasks that they were not originally trained on / or fine tuned for. A task can be described in text with few labeled examples (few-shot) or no example at all (zero-shot), and then an unlabeled example is appended to the text and the LLM is asked to complete the text just like any normal Text Generation task. The collection of the task description and optionally the labeled examples is known as the prompt.  


